{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d7e3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tonyavis/Main/AI_public_projects/object_detection/yolo_v1_taco\n"
     ]
    }
   ],
   "source": [
    "# === Note: Runs this jupyter notebook from the projects root, mimicking a root run.\n",
    "import os\n",
    "os.chdir(os.getcwd().rsplit(\"/\", 1)[0])\n",
    "print(os.getcwd())\n",
    "\n",
    "import torch\n",
    "# Show all values when printing torch tensors.\n",
    "torch.set_printoptions(threshold=torch.inf) # shows all the values when printing tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a3a288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(DEVICE=device(type='mps'), NUM_WORKERS=2, PIN_MEMORY=True, EPOCHS=25, LEARNING_RATE=0.001, BATCH_SIZE=64, WEIGHT_DECAY=0, CON_TRAINING=False, LOAD_MODEL_FILE='yolo_v1_taco_D_2025-07-10_EPOCH_50_LOSS_4.4416_SIZE_448.pt', LAST_EPOCH=0, WHICH_DATASET='test-case-overfit-one-image', IMAGE_SIZE=448, C=18, B=2, S=7, IOU_THRESHOLD=0.6, MIN_THRESHOLD=0.5, NUM_NODES_PER_CELL=28, NUM_NODES_PER_IMG=1372)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.load_config import load_config\n",
    "config = load_config()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5757dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b16fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract bounding boxes\n",
    "# NOTE: Do not implement this function before the loss_fn(). Use this function before plot_bboxes(), and non_max_suppression().\n",
    "def extract_bboxes(t: torch.Tensor, config: Namespace):\n",
    "    \"\"\"\n",
    "    Extract bounding boxes from a single image's (predicted or labeled) tensor, converting them into a flat (N, 9) representation, and finally sorting based on their probability score (pc) in descending order.\n",
    "\n",
    "    Note:\n",
    "        - N = S * S * B or total number of bboxes per image.\n",
    "        - Nested 9 nodes looks like -> [i, j, b, class_idx, pc, x, y, w, h], sorted by pc descending for each image.\n",
    "        - i,j is the bboxes cell location in the grid.\n",
    "        - b is if the bbox is either bbox1 or bbox2 in its cell. Its value is either 0 or 1.\n",
    "        - pc is the probability score that an object exists in that cell.\n",
    "        - class_idx is a value between 0 and 17 that indicates which object the cell predicts to be present. It’s obtained by applying argmax() to the class object probability scores at indices 0 through 17. Note object probability scores here is not the same as pc.\n",
    "        - The return tensor will have bboxes sorted by pc (descending).\n",
    "\n",
    "    Args:\n",
    "        t (tensor) : Shape (S, S, NUM_NODES_PER_CELL)\n",
    "\n",
    "    Returns:\n",
    "        (tensor) : shape (S * S * B , 9), Sorted by bboxes with the highest pc at the beginning. [[ i, j, b, class_idx, pc, x, y, w, h]] -> num nodes = 9.\n",
    "    \"\"\"\n",
    "    S, B, C, DEVICE, NUM_NODES_PER_CELL = (\n",
    "        config.S,\n",
    "        config.B,\n",
    "        config.C,\n",
    "        config.DEVICE,\n",
    "        config.NUM_NODES_PER_CELL,\n",
    "    )\n",
    "\n",
    "    # === 1: Create new tensors to store class probs, first bbox and second bbox from every cell across the batch.\n",
    "    class_probs = t[..., :C]  # ( S, S, C)\n",
    "\n",
    "    bbox_1 = t[..., C : C + 5]  # ( S, S, 5) #pc1, x1, y1, w1, h1\n",
    "    bbox_2 = t[..., C + 5 : NUM_NODES_PER_CELL]  # ( S, S, 5)\n",
    "    bboxes = torch.stack([bbox_1, bbox_2], dim=2)  # shape: ( S, S, 2, 5)\n",
    "\n",
    "    # #   Get the highest predicted object from indexes 0-17. Store as index.\n",
    "    class_idx = class_probs.argmax(dim=-1)  # shape: ( S, S)\n",
    "\n",
    "    # === 2: Create grid cell indice mapping tensor for i, j, and b coords.\n",
    "    # Note: (i,j) -> i = row_indices and j = col_indices.\\\n",
    "\n",
    "    row_indices, col_indices = torch.meshgrid(\n",
    "        torch.arange(S, device=DEVICE), torch.arange(S, device=DEVICE), indexing=\"ij\"\n",
    "    )  # (S, S)\n",
    "    \n",
    "    # Create a grid cell to keep track of what bounding box in a cell has the high probability score.\n",
    "    box_indices = (\n",
    "        torch.arange(B, device=DEVICE).view(1, 1, B).expand(S, S, B)\n",
    "    )  # (S, S, 2)\n",
    "    print(\"box_indices:\",box_indices, \"\\n\\n\")\n",
    "\n",
    "    #       Reshape and expand row and col indices to include the number bounding boxes per cell.\n",
    "    row_indices = row_indices.unsqueeze(-1).expand(\n",
    "        -1, -1, B\n",
    "    )  # from (S, S) -> (S, S, 2)\n",
    "\n",
    "    col_indices = col_indices.unsqueeze(-1).expand(\n",
    "        -1, -1, B\n",
    "    )  # from (S, S) -> (S, S, 2)\n",
    "\n",
    "    # === 3: Expand class_idx tensor to match (S, S, 2)\n",
    "    cls_indices = class_idx.unsqueeze(-1).expand(\n",
    "        -1, -1, B\n",
    "    )  # (7, 7) -> (7, 7, 2)\n",
    "    print(cls_indices.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # # === 4: Stack metadata\n",
    "    # metadata = torch.stack(\n",
    "    #     [row_indices, col_indices, box_indices], dim=-1\n",
    "    # )  # (7, 7, 2, 3)\n",
    "\n",
    "    # cls_indices = cls_indices.unsqueeze(-1)  # ( 7, 7, 2) -> ( 7, 7, 2, 1)\n",
    "\n",
    "    # #       Concatenate: (S, S , 2, 9) 9 = [i, j, b, class_idx, pc, x, y, w, h]\n",
    "    # full = torch.cat(\n",
    "    #     [metadata.float(), cls_indices.float(), bboxes], dim=-1\n",
    "    # )  # (7, 7, 2, 9)\n",
    "\n",
    "    # #      Reshape full into flat form: ( S, S, 2, 9) -> ( N, 9) where N=S*S*2 or total num bboxes per image.\n",
    "    # full = full.view( -1, 9)\n",
    "\n",
    "    # # === 5: Sort by pc (column 4)\n",
    "    # sorted_indices = full[:, 4].argsort(\n",
    "    #     descending=True\n",
    "    # )\n",
    "\n",
    "    # return full.index_select(\n",
    "    #     0, sorted_indices\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb18411",
   "metadata": {},
   "source": [
    "**Create a tensor That mimics labeled data with easily identifiable values at locations like pc1, class_idx, x, y, w, h**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58ef406b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "           14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.]]]),\n",
       " 'Size:',\n",
       " torch.Size([1, 1, 28]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S, B, C = 1, 2, 18  # Grid size, num boxes, num classes\n",
    "config.S = S\n",
    "\n",
    "out = torch.zeros(S, S, C + B * 5)\n",
    "\n",
    "out[:, :, 18] = torch.rand(S, S) * 5 + 15\n",
    "for i in range(28): #number of nodes in a cell\\\n",
    "    out[:, :, i] = i\n",
    "\n",
    "out, \"Size:\", out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c37f2525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "           11.,  12.,  13.,  14.,  15.,  16.,  17., 100., 100., 100., 100.,\n",
       "          100.,  23.,  24.,  25.,  26.,  27.]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:, :, 18:23] = 100\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9f60492e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box_indices: tensor([[[0, 1]]], device='mps:0') \n",
      "\n",
      "\n",
      "torch.Size([1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "extract_bboxes(out, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bboxes(t: torch.Tensor, cfg: Namespace):\n",
    "    \"\"\"\n",
    "    Flatten a single YOLO-v1 grid (S×S×(C+5B)) into (N, 9) rows sorted by pc.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor  # (S*S*B, 9) with columns:\n",
    "        0  i   row index in grid\n",
    "        1  j   col index in grid\n",
    "        2  b   0 or 1  (which of the two boxes in the cell)\n",
    "        3  cls class-index ∈[0, C-1]\n",
    "        4  pc  object-confidence\n",
    "        5-8    x, y, w, h (relative coords)\n",
    "    \"\"\"\n",
    "    S, B, C = cfg.S, cfg.B, cfg.C\n",
    "    device = t.device                           # robust to mixed devices\n",
    "    nodes = t.shape[-1]\n",
    "    assert nodes == C + 5 * B, \\\n",
    "        f\"Expected {C + 5 * B} nodes per cell, got {nodes}\"\n",
    "\n",
    "    # --- slice\n",
    "    class_probs = t[..., :C]                    # (S,S,C)\n",
    "    box_raw     = t[..., C:].reshape(S, S, B, 5)  # (S,S,B,5)\n",
    "\n",
    "    # --- metadata tensors (int64 throughout)\n",
    "    i_idx, j_idx = torch.meshgrid(\n",
    "        torch.arange(S, device=device),\n",
    "        torch.arange(S, device=device),\n",
    "        indexing='ij'\n",
    "    )\n",
    "    i_idx = i_idx.unsqueeze(-1).expand(-1, -1, B)    # (S,S,B)\n",
    "    j_idx = j_idx.unsqueeze(-1).expand(-1, -1, B)\n",
    "    b_idx = torch.arange(B, device=device).view(1, 1, B).expand(S, S, B)\n",
    "\n",
    "    cls_idx = class_probs.argmax(-1).unsqueeze(-1).expand(-1, -1, B)  # (S,S,B)\n",
    "\n",
    "    # --- stack [i,j,b,cls,pc,x,y,w,h]; keep ints for first 4 cols\n",
    "    header = torch.stack([i_idx, j_idx, b_idx, cls_idx], dim=-1)       # (S,S,B,4)\n",
    "    full   = torch.cat([header, box_raw], dim=-1)                      # (S,S,B,9)\n",
    "\n",
    "    full = full.reshape(-1, 9)                                         # (N,9)\n",
    "    order = full[:, 4].argsort(descending=True)\n",
    "    return full.index_select(0, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c9296e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   0.,   0.,  17., 100., 100., 100., 100., 100.],\n",
       "        [  0.,   0.,   1.,  17.,  23.,  24.,  25.,  26.,  27.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_bboxes(t=out, cfg=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19392bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
