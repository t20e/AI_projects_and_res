{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6012ec55",
   "metadata": {},
   "source": [
    "# AutoEncoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b86e2cb",
   "metadata": {},
   "source": [
    "ðŸ’¡ Basic Purpose: A model that attempts to describe very large data with as few features as possible.\n",
    "\n",
    "AutoEncoders have an **Encoder** and **Decoder**.\n",
    "\n",
    "1. The **Encoder** takes the input data and reduces it to a smaller, compressed representation called the **latent space**\n",
    "\n",
    "2. The **latent space** is a low-dimensional space that captures the essential features of the input data.\n",
    "\n",
    "3. The **Decoder** then takes this compressed representation and tries to reconstruct the original data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55484d8",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"../showcase_images/autoEncoders.png\" alt=\"auto encoder network\" width=\"300\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbff5f6",
   "metadata": {},
   "source": [
    "- The **goal** is to make the reconstructed output as close to the original input as possible, while minimizing the reconstruction error. Autoencoders are commonly used for tasks like dimensionality reduction and data denoising."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba2bd0",
   "metadata": {},
   "source": [
    "**Latent Space**\n",
    "\n",
    "The number of **neurons** in the latent space *layer* determines how many dimensions the Encoded data will be represented as.\n",
    "-  In the above example we have 3 neurons so the **encoded data** will be represented in 3D space, if it were 5 it would be represented in 5D space.\n",
    "\n",
    "*Latent Space Example Plot:*\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"../showcase_images/LatentSpaceRepresentation.png\" alt=\"auto encoder network\" width=\"500\">\n",
    "</p>\n",
    "\n",
    "- Note the one image of a number 7 that is near the 0's cluster, because that point is in a region the decoder has learned to associate with the features of a \"0\", the reconstruction will likely be poor. The resulting image might look like a blurry \"0\", or an ambiguous shape that's a mix of a \"7\" and a \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba488f3",
   "metadata": {},
   "source": [
    "**AutoEncoderÂ Use-Cases**\n",
    "- Dimensionality Reduction\n",
    "- Image Compression\n",
    "- Image denoising\n",
    "- Anomaly detection\n",
    "- Feature extraction\n",
    "\n",
    "**Limitations**\n",
    "- Overfitting: The model might simple just copy the input to the output without learning a meaningful compressed representation.\n",
    "- Lack of Generative capability (VAE models are used for this purpose)\n",
    "- Computational cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c81d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32503c36",
   "metadata": {},
   "source": [
    "# Torch Implementation With MNIST Dataset\n",
    "\n",
    "â­ï¸ The MNIST dataset was used in -> [../basic_NN_multi-class-classification.ipynb](../basic_NN_multi-class-classification.ipynb), review it to understand the dataset. However, we will download the torch MNIST for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f6a0c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc80f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device for training (GPU if available, otherwise CPU), note: mps is for the Mac silicone.\n",
    "DEVICE = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5270f0da",
   "metadata": {},
   "source": [
    "### Get The Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "997a8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading and Preprocessing ---\n",
    "# Define a transform to convert images to tensors\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Download and load the MNIST training and test datasets if it wasn't already downloaded, else load it.\n",
    "train_dataset = datasets.MNIST(root='../datasets', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='../datasets', train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960a2dfd",
   "metadata": {},
   "source": [
    "### AutoEncoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a76c3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hyperparameters ---\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LATENT_DIM = 16 # The size of our compressed latent space representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2205dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5517cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        # Encoder: Converts input data into a compressed latent representation\n",
    "        self.encoder = nn.Sequential(\n",
    "            # Input: the MNIST dataset is labeled as [batch_size, 1, 28, 28]\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Latent space: Flatten the output of the encoder\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_encode = nn.Linear(64 * 4 * 4, LATENT_DIM)\n",
    "\n",
    "        # Decoder: Reconstructs image from latent representation\n",
    "        self.fc_decode = nn.Linear(LATENT_DIM, 64 * 4 * 4, LATENT_DIM)\n",
    "        self.unflatten = nn.Unflatten(1, (64,4,4))\n",
    "        self.decoder =nn.Sequential(\n",
    "            # Input: is the latent representation [batch_size, 64, 4, 4]\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid() # sigmoid to enure output is between 0 and 1 \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        flattened = self.flatten(encoded)\n",
    "        latent = self.fc_encode(flattened)\n",
    "        \n",
    "        decoded_flattened = self.fc_decode(latent)\n",
    "        decoded = self.unflatten(decoded_flattened)\n",
    "        reconstructed = self.decoder(decoded)\n",
    "        return reconstructed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1534cbee",
   "metadata": {},
   "source": [
    "`Initialize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bb41672",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder().to(DEVICE)\n",
    "criterion = nn.MSELoss() # Mean Squared Error is a common loss function for autoencoders\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ca744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
